{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85395b50",
   "metadata": {},
   "source": [
    "# WithColumn function in Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0800ff18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PySpark withColumn() is a transformation function of DataFrame which is used to change the value, convert the datatype of \\n   an existing column, create a new column, and many more'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''PySpark withColumn() is a transformation function of DataFrame which is used to change the value, convert the datatype of \n",
    "   an existing column, create a new column, and many more'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae157428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fac7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6672f0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|       xxx|   Smith|1991-04-01|     M|  3000|\n",
      "|  Michael|      Rose|     yyy|2000-05-19|     M|  4000|\n",
      "|   Robert|       aaa|Williams|1978-09-05|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [('James','xxx','Smith','1991-04-01','M','3000'),\n",
    "  ('Michael','Rose','yyy','2000-05-19','M','4000'),\n",
    "  ('Robert','aaa','Williams','1978-09-05','M','4000'),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F','4000'),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F','-1')]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d4890",
   "metadata": {},
   "source": [
    "# 1. Change DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aafe465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+-------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|salary1|\n",
      "+---------+----------+--------+----------+------+------+-------+\n",
      "|    James|       xxx|   Smith|1991-04-01|     M|  3000|   3000|\n",
      "|  Michael|      Rose|     yyy|2000-05-19|     M|  4000|   4000|\n",
      "|   Robert|       aaa|Williams|1978-09-05|     M|  4000|   4000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|   4000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|     -1|\n",
      "+---------+----------+--------+----------+------+------+-------+\n",
      "\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- salary1: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df1 = df.withColumn(\"salary1\",col(\"salary\").cast(\"Integer\"))\n",
    "\n",
    "df1.show()\n",
    "df1.printSchema()\n",
    "\n",
    "#--->df.na.fill(0)\n",
    "#--->df.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561bbde7",
   "metadata": {},
   "source": [
    "# 2. Update The Value of an Existing Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60140780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+-------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|salary1|\n",
      "+---------+----------+--------+----------+------+------+-------+\n",
      "|    James|       xxx|   Smith|1991-04-01|     M|  3000| 300000|\n",
      "|  Michael|      Rose|     yyy|2000-05-19|     M|  4000| 400000|\n",
      "|   Robert|       aaa|Williams|1978-09-05|     M|  4000| 400000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000| 400000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|   -100|\n",
      "+---------+----------+--------+----------+------+------+-------+\n",
      "\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- salary1: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df1.withColumn(\"salary1\",col(\"salary1\")*100).show()\n",
    "df1.withColumn(\"salary1\",col(\"salary1\")*100).printSchema()\n",
    "\n",
    "df.withColumn()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5a04ec",
   "metadata": {},
   "source": [
    "# 3. Create a Column from an Existing Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "586a241f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+---------------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|           Name|\n",
      "+---------+----------+--------+----------+------+------+---------------+\n",
      "|    James|       xxx|   Smith|1991-04-01|     M|  3000|    James-Smith|\n",
      "|  Michael|      Rose|     yyy|2000-05-19|     M|  4000|    Michael-yyy|\n",
      "|   Robert|       aaa|Williams|1978-09-05|     M|  4000|Robert-Williams|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|    Maria-Jones|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|      Jen-Brown|\n",
      "+---------+----------+--------+----------+------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat, col, lit\n",
    "\n",
    "#df.withColumn(\"CopiedColumn\",col(\"salary\")* -1).show()\n",
    "df.withColumn(\"Name\", concat(col(\"firstname\"),lit('-'),col(\"lastname\"))).show()\n",
    "\n",
    "#help(df.concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9dd1dc",
   "metadata": {},
   "source": [
    "# 4. Add a New Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89ec75ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+-------+----+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|Country|DEPT|\n",
      "+---------+----------+--------+----------+------+------+-------+----+\n",
      "|    James|       xxx|   Smith|1991-04-01|     M|  3000|    USA|  IT|\n",
      "|  Michael|      Rose|     yyy|2000-05-19|     M|  4000|    USA|  IT|\n",
      "|   Robert|       aaa|Williams|1978-09-05|     M|  4000|    USA|  IT|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|    USA|  IT|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|    USA|  IT|\n",
      "+---------+----------+--------+----------+------+------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "#df.withColumn(\"Country\", lit(\"USA\")).show()\n",
    "df.withColumn(\"Country\", lit(\"USA\")) \\\n",
    "  .withColumn(\"DEPT\",lit(\"IT\")) \\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6886b181",
   "metadata": {},
   "source": [
    "# 5. Rename Column Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f2e65d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+---+------+\n",
      "|firstname|middlename|lastname|dob       |sex|salary|\n",
      "+---------+----------+--------+----------+---+------+\n",
      "|James    |xxx       |Smith   |1991-04-01|M  |3000  |\n",
      "|Michael  |Rose      |yyy     |2000-05-19|M  |4000  |\n",
      "|Robert   |aaa       |Williams|1978-09-05|M  |4000  |\n",
      "|Maria    |Anne      |Jones   |1967-12-01|F  |4000  |\n",
      "|Jen      |Mary      |Brown   |1980-02-17|F  |-1    |\n",
      "+---------+----------+--------+----------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"gender\",\"sex\") \\\n",
    "  .show(truncate=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2cd4c7",
   "metadata": {},
   "source": [
    "# WithColumnRenamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "339eb480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary_amount: string (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----------+------+-------------+\n",
      "|firstname|middlename|lastname|DateOfBirth|gender|salary_amount|\n",
      "+---------+----------+--------+-----------+------+-------------+\n",
      "|    James|       xxx|   Smith| 1991-04-01|     M|         3000|\n",
      "|  Michael|      Rose|     yyy| 2000-05-19|     M|         4000|\n",
      "|   Robert|       aaa|Williams| 1978-09-05|     M|         4000|\n",
      "|    Maria|      Anne|   Jones| 1967-12-01|     F|         4000|\n",
      "|      Jen|      Mary|   Brown| 1980-02-17|     F|           -1|\n",
      "+---------+----------+--------+-----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2 = df.withColumnRenamed(\"dob\",\"DateOfBirth\") \\\n",
    "        .withColumnRenamed(\"salary\",\"salary_amount\")\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2c63986",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be758a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
